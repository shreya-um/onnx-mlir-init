{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rFWn9JlVR7-b"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting PyYAML (from yacs)\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
            "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 30.7/144.7 kB ? eta -:--:--\n",
            "   --------------------------------- ------ 122.9/144.7 kB 1.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  143.4/144.7 kB 1.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 144.7/144.7 kB 1.1 MB/s eta 0:00:00\n",
            "Installing collected packages: PyYAML, yacs\n",
            "Successfully installed PyYAML-6.0.1 yacs-0.1.8\n",
            "Requirement already satisfied: scipy in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.13.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scipy) (1.26.4)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
            "     ----------------------------------- ---- 51.2/57.6 kB 1.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 57.6/57.6 kB 1.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: colorama in c:\\users\\berne\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
            "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
            "   ------------------------------------ --- 71.7/78.3 kB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 78.3/78.3 kB 2.2 MB/s eta 0:00:00\n",
            "Installing collected packages: tqdm\n",
            "Successfully installed tqdm-4.66.4\n",
            "Requirement already satisfied: yacs in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yacs) (6.0.1)\n",
            "Collecting Cython\n",
            "  Downloading Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
            "Downloading Cython-3.0.10-cp311-cp311-win_amd64.whl (2.8 MB)\n",
            "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.1/2.8 MB 3.6 MB/s eta 0:00:01\n",
            "   -- ------------------------------------- 0.2/2.8 MB 2.0 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 0.4/2.8 MB 3.3 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 0.5/2.8 MB 3.1 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 0.6/2.8 MB 3.0 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 0.8/2.8 MB 3.0 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 0.9/2.8 MB 3.0 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 1.1/2.8 MB 2.9 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 1.1/2.8 MB 2.7 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.2/2.8 MB 2.8 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.3/2.8 MB 2.7 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.4/2.8 MB 2.7 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 1.6/2.8 MB 2.8 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.6/2.8 MB 2.7 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.6/2.8 MB 2.5 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 1.7/2.8 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 1.8/2.8 MB 2.4 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 1.9/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 2.0/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 2.1/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 2.2/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 2.3/2.8 MB 2.4 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 2.4/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 2.5/2.8 MB 2.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 2.6/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.7/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.8/2.8 MB 2.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.8/2.8 MB 2.2 MB/s eta 0:00:00\n",
            "Installing collected packages: Cython\n",
            "Successfully installed Cython-3.0.10\n",
            "Requirement already satisfied: Pillow in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.3.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\berne\\appdata\\roaming\\python\\python311\\site-packages (from tensorboardX) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX) (4.25.3)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
            "   ---- ----------------------------------- 10.2/101.7 kB ? eta -:--:--\n",
            "   ---- ----------------------------------- 10.2/101.7 kB ? eta -:--:--\n",
            "   ------- ------------------------------- 20.5/101.7 kB 108.9 kB/s eta 0:00:01\n",
            "   ------- ------------------------------- 20.5/101.7 kB 108.9 kB/s eta 0:00:01\n",
            "   ------- ------------------------------- 20.5/101.7 kB 108.9 kB/s eta 0:00:01\n",
            "   ------- ------------------------------- 20.5/101.7 kB 108.9 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ------------ --------------------------- 30.7/101.7 kB 77.0 kB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 41.0/101.7 kB 28.1 kB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 41.0/101.7 kB 28.1 kB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 41.0/101.7 kB 28.1 kB/s eta 0:00:03\n",
            "   ---------------- ----------------------- 41.0/101.7 kB 28.1 kB/s eta 0:00:03\n",
            "   -------------------------------- ------- 81.9/101.7 kB 54.6 kB/s eta 0:00:01\n",
            "   -------------------------------- ------- 81.9/101.7 kB 54.6 kB/s eta 0:00:01\n",
            "   --------------------------------------- 101.7/101.7 kB 65.0 kB/s eta 0:00:00\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.8.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\berne\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\berne\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\berne\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "   ---------------------------------------- 0.0/294.9 kB ? eta -:--:--\n",
            "   ----- ---------------------------------- 41.0/294.9 kB ? eta -:--:--\n",
            "   ----------- ---------------------------- 81.9/294.9 kB 1.1 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 163.8/294.9 kB 1.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 245.8/294.9 kB 1.7 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 245.8/294.9 kB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 294.9/294.9 kB 1.1 MB/s eta 0:00:00\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.2\n",
            "Collecting prefetch_generator\n",
            "  Downloading prefetch_generator-1.0.3.tar.gz (4.6 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Installing backend dependencies: started\n",
            "  Installing backend dependencies: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Building wheels for collected packages: prefetch_generator\n",
            "  Building wheel for prefetch_generator (pyproject.toml): started\n",
            "  Building wheel for prefetch_generator (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for prefetch_generator: filename=prefetch_generator-1.0.3-py3-none-any.whl size=4769 sha256=44bdeae5aa0ff1606318324b213717b311d4697072fb51b63176a89e427ae4c6\n",
            "  Stored in directory: c:\\users\\berne\\appdata\\local\\pip\\cache\\wheels\\9b\\08\\01\\8bacc997ecb83922063bc7dadb42f3cb52cfe43b5217caf820\n",
            "Successfully built prefetch_generator\n",
            "Installing collected packages: prefetch_generator\n",
            "Successfully installed prefetch_generator-1.0.3\n",
            "Collecting imageio\n",
            "  Downloading imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imageio) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imageio) (10.3.0)\n",
            "Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
            "   ---------------------------------------- 0.0/313.5 kB ? eta -:--:--\n",
            "   --- ----------------------------------- 30.7/313.5 kB 660.6 kB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 92.2/313.5 kB 1.1 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 174.1/313.5 kB 1.3 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 286.7/313.5 kB 1.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 313.5/313.5 kB 1.5 MB/s eta 0:00:00\n",
            "Installing collected packages: imageio\n",
            "Successfully installed imageio-2.34.1\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\berne\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yacs\n",
        "!pip install scipy\n",
        "!pip install tqdm\n",
        "!pip install yacs\n",
        "!pip install Cython\n",
        "!pip install matplotlib>=3.2.2\n",
        "!pip install numpy>=1.18.5\n",
        "!pip install opencv-python>=4.1.2\n",
        "!pip install Pillow\n",
        "!pip install PyYAML>=5.3\n",
        "!pip install scipy>=1.4.1\n",
        "!pip install tensorboardX\n",
        "!pip install seaborn\n",
        "!pip install prefetch_generator\n",
        "!pip install imageio\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRPgvXu-R7-k"
      },
      "source": [
        "(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime\n",
        "===================================================================================\n",
        "\n",
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "<p>As of PyTorch 2.1, there are two versions of ONNX Exporter.</p>\n",
        "</div>\n",
        "\n",
        "In this tutorial, we describe how to convert a model defined in PyTorch\n",
        "into the ONNX format using the TorchScript\n",
        "[\\`torch.onnx.export]{.title-ref} ONNX exporter.\n",
        "\n",
        "The exported model will be executed with ONNX Runtime. ONNX Runtime is a\n",
        "performance-focused engine for ONNX models, which inferences efficiently\n",
        "across multiple platforms and hardware (Windows, Linux, and Mac and on\n",
        "both CPUs and GPUs). ONNX Runtime has proved to considerably increase\n",
        "performance over multiple models as explained\n",
        "[here](https://cloudblogs.microsoft.com/opensource/2019/05/22/onnx-runtime-machine-learning-inferencing-0-4-release)\n",
        "\n",
        "For this tutorial, you will need to install\n",
        "[ONNX](https://github.com/onnx/onnx) and [ONNX\n",
        "Runtime](https://github.com/microsoft/onnxruntime). You can get binary\n",
        "builds of ONNX and ONNX Runtime with\n",
        "\n",
        "``` {.sourceCode .bash}\n",
        "%%bash\n",
        "pip install onnx onnxruntime\n",
        "```\n",
        "\n",
        "ONNX Runtime recommends using the latest stable runtime for PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua4gtthyTZEk",
        "outputId": "be3a5512-9f19-4eac-c308-769319d70f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.17.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lAl9MD2dR7-p"
      },
      "outputs": [],
      "source": [
        "# Some standard imports\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvczqTpUR7-q"
      },
      "source": [
        "Super-resolution is a way of increasing the resolution of images, videos\n",
        "and is widely used in image processing or video editing. For this\n",
        "tutorial, we will use a small super-resolution model.\n",
        "\n",
        "First, let\\'s create a `SuperResolution` model in PyTorch. This model\n",
        "uses the efficient sub-pixel convolution layer described in [\\\"Real-Time\n",
        "Single Image and Video Super-Resolution Using an Efficient Sub-Pixel\n",
        "Convolutional Neural Network\\\" - Shi et\n",
        "al](https://arxiv.org/abs/1609.05158) for increasing the resolution of\n",
        "an image by an upscale factor. The model expects the Y component of the\n",
        "`YCbCr` of an image as an input, and outputs the upscaled Y component in\n",
        "super resolution.\n",
        "\n",
        "[The\n",
        "model](https://github.com/pytorch/examples/blob/master/super_resolution/model.py)\n",
        "comes directly from PyTorch\\'s examples without modification:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qYt0WE7FR7-r"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/hustvl/yolop/zipball/main\" to C:\\Users\\Berne/.cache\\torch\\hub\\main.zip\n"
          ]
        }
      ],
      "source": [
        "# Create the yolop model by using the above model definition.\n",
        "torch_model = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbxyeDh6R7-s"
      },
      "source": [
        "Ordinarily, you would now train this model; however, for this tutorial,\n",
        "we will instead download some pretrained weights. Note that this model\n",
        "was not trained fully for good accuracy and is used here for\n",
        "demonstration purposes only.\n",
        "\n",
        "It is important to call `torch_model.eval()` or\n",
        "`torch_model.train(False)` before exporting the model, to turn the model\n",
        "to inference mode. This is required since operators like dropout or\n",
        "batchnorm behave differently in inference and training mode.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heU-gYRPR7-v"
      },
      "source": [
        "Exporting a model in PyTorch works via tracing or scripting. This\n",
        "tutorial will use as an example a model exported by tracing. To export a\n",
        "model, we call the `torch.onnx.export()` function. This will execute the\n",
        "model, recording a trace of what operators are used to compute the\n",
        "outputs. Because `export` runs the model, we need to provide an input\n",
        "tensor `x`. The values in this can be random as long as it is the right\n",
        "type and size. Note that the input size will be fixed in the exported\n",
        "ONNX graph for all the input\\'s dimensions, unless specified as a\n",
        "dynamic axes. In this example we export the model with an input of\n",
        "batch\\_size 1, but then specify the first dimension as dynamic in the\n",
        "`dynamic_axes` parameter in `torch.onnx.export()`. The exported model\n",
        "will thus accept inputs of size \\[batch\\_size, 1, 224, 224\\] where\n",
        "batch\\_size can be variable.\n",
        "\n",
        "To learn more details about PyTorch\\'s export interface, check out the\n",
        "[torch.onnx documentation](https://pytorch.org/docs/master/onnx.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e3jp0XEoR7-x"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:199: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4]:\n"
          ]
        },
        {
          "ename": "SymbolicValueError",
          "evalue": "Unsupported: ONNX export of index_put in opset 9. Please try opset version 11.  [Caused by the value '1113 defined in (%1113 : Float(*, 3, 80, 80, 6, strides=[115200, 38400, 480, 6, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%1110), scope: lib.models.YOLOP.MCnet::/lib.models.common.Detect::model.24 # C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:201:0\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Sigmoid'.] \n    (node defined in C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py(201): forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1522): _slow_forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\nC:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\YOLOP.py(555): forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1522): _slow_forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\jit\\_trace.py(129): wrapper\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\jit\\_trace.py(138): forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\jit\\_trace.py(1310): _get_trace_graph\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(914): _trace_and_get_graph_from_model\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(1010): _create_jit_graph\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(1134): _model_to_graph\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(1612): _export\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(516): export\nC:\\Users\\Berne\\AppData\\Local\\Temp\\ipykernel_15124\\526370162.py(6): <module>\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3577): run_code\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3517): run_ast_nodes\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3334): run_cell_async\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py(129): _pseudo_sync_runner\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3130): _run_cell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3075): run_cell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(534): process_one\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py(84): _run\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py(1936): _run_once\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py(608): run_forever\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py(205): start\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py(739): start\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py(18): <module>\n<frozen runpy>(88): _run_code\n<frozen runpy>(198): _run_module_as_main\n)\n\n    Inputs:\n        #0: 1110 defined in (%1110 : Float(*, 3, 80, 80, 6, strides=[115200, 38400, 480, 6, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1108, %1109), scope: lib.models.YOLOP.MCnet::/lib.models.common.Detect::model.24 # C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:194:0\n    )  (type 'Tensor')\n    Outputs:\n        #0: 1113 defined in (%1113 : Float(*, 3, 80, 80, 6, strides=[115200, 38400, 480, 6, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%1110), scope: lib.models.YOLOP.MCnet::/lib.models.common.Detect::model.24 # C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:201:0\n    )  (type 'Tensor')",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mSymbolicValueError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m torch_out \u001b[38;5;241m=\u001b[39m torch_model(img)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Export the model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# model being run\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# model input (or a tuple for multiple inputs)\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolop.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# where to save the model (can be a file or file-like object)\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# store the trained parameter weights inside the model file\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# the ONNX version to export the model to\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# whether to execute constant folding for optimization\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# the model's input names\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m                  \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# the model's output names\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# variable length axes\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[0;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:1612\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[0;32m   1609\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1610\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[1;32m-> 1612\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1623\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1627\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[0;32m   1628\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:1138\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[0;32m   1135\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1138\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1149\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:677\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[1;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[0;32m    674\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[0;32m    675\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m--> 677\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m    679\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:1956\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[1;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[0;32m   1951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m symbolic_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1952\u001b[0m         \u001b[38;5;66;03m# TODO Wrap almost identical attrs assignment or comment the difference.\u001b[39;00m\n\u001b[0;32m   1953\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1954\u001b[0m             k: symbolic_helper\u001b[38;5;241m.\u001b[39m_node_get(node, k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()\n\u001b[0;32m   1955\u001b[0m         }\n\u001b[1;32m-> 1956\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msymbolic_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1958\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1959\u001b[0m     k \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39mkindOf(k)[\u001b[38;5;241m0\u001b[39m]: symbolic_helper\u001b[38;5;241m.\u001b[39m_node_get(node, k)\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()\n\u001b[0;32m   1961\u001b[0m }\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1963\u001b[0m     \u001b[38;5;66;03m# Clone node to trigger ONNX shape inference\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:7152\u001b[0m, in \u001b[0;36monnx_placeholder\u001b[1;34m(g, *inputs, **attrs)\u001b[0m\n\u001b[0;32m   7149\u001b[0m block \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mblock\n\u001b[0;32m   7150\u001b[0m env \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39menv\n\u001b[1;32m-> 7152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_onnx_convert_pattern_from_subblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:1956\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[1;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[0;32m   1951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m symbolic_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1952\u001b[0m         \u001b[38;5;66;03m# TODO Wrap almost identical attrs assignment or comment the difference.\u001b[39;00m\n\u001b[0;32m   1953\u001b[0m         attrs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1954\u001b[0m             k: symbolic_helper\u001b[38;5;241m.\u001b[39m_node_get(node, k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()\n\u001b[0;32m   1955\u001b[0m         }\n\u001b[1;32m-> 1956\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msymbolic_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1958\u001b[0m attrs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1959\u001b[0m     k \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m node\u001b[38;5;241m.\u001b[39mkindOf(k)[\u001b[38;5;241m0\u001b[39m]: symbolic_helper\u001b[38;5;241m.\u001b[39m_node_get(node, k)\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()\n\u001b[0;32m   1961\u001b[0m }\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1963\u001b[0m     \u001b[38;5;66;03m# Clone node to trigger ONNX shape inference\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:3205\u001b[0m, in \u001b[0;36mindex_put\u001b[1;34m(g, self, indices_list_value, values, accumulate)\u001b[0m\n\u001b[0;32m   3203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m add(g, \u001b[38;5;28mself\u001b[39m, values)\n\u001b[0;32m   3204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m-> 3205\u001b[0m \u001b[43msymbolic_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_onnx_opset_unsupported\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex_put\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\symbolic_helper.py:642\u001b[0m, in \u001b[0;36m_onnx_opset_unsupported\u001b[1;34m(op_name, current_opset, supported_opset, value)\u001b[0m\n\u001b[0;32m    637\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported: ONNX export of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mop_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in opset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_opset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease try opset version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_opset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    640\u001b[0m )\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, _C\u001b[38;5;241m.\u001b[39mValue):\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mSymbolicValueError(\n\u001b[0;32m    643\u001b[0m         message,\n\u001b[0;32m    644\u001b[0m         value,\n\u001b[0;32m    645\u001b[0m     )\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOnnxExporterError(message)\n",
            "\u001b[1;31mSymbolicValueError\u001b[0m: Unsupported: ONNX export of index_put in opset 9. Please try opset version 11.  [Caused by the value '1113 defined in (%1113 : Float(*, 3, 80, 80, 6, strides=[115200, 38400, 480, 6, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%1110), scope: lib.models.YOLOP.MCnet::/lib.models.common.Detect::model.24 # C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:201:0\n)' (type 'Tensor') in the TorchScript graph. The containing node has kind 'onnx::Sigmoid'.] \n    (node defined in C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py(201): forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1522): _slow_forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\nC:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\YOLOP.py(555): forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1522): _slow_forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\jit\\_trace.py(129): wrapper\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\jit\\_trace.py(138): forward\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1541): _call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py(1532): _wrapped_call_impl\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\jit\\_trace.py(1310): _get_trace_graph\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(914): _trace_and_get_graph_from_model\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(1010): _create_jit_graph\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(1134): _model_to_graph\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(1612): _export\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py(516): export\nC:\\Users\\Berne\\AppData\\Local\\Temp\\ipykernel_15124\\526370162.py(6): <module>\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3577): run_code\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3517): run_ast_nodes\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3334): run_cell_async\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py(129): _pseudo_sync_runner\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3130): _run_cell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py(3075): run_cell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py(549): run_cell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py(449): do_execute\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(778): execute_request\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py(362): execute_request\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(437): dispatch_shell\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(534): process_one\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py(545): dispatch_queue\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py(84): _run\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py(1936): _run_once\nc:\\Users\\Berne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py(608): run_forever\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py(205): start\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py(739): start\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py(1075): launch_instance\nC:\\Users\\Berne\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py(18): <module>\n<frozen runpy>(88): _run_code\n<frozen runpy>(198): _run_module_as_main\n)\n\n    Inputs:\n        #0: 1110 defined in (%1110 : Float(*, 3, 80, 80, 6, strides=[115200, 38400, 480, 6, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1108, %1109), scope: lib.models.YOLOP.MCnet::/lib.models.common.Detect::model.24 # C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:194:0\n    )  (type 'Tensor')\n    Outputs:\n        #0: 1113 defined in (%1113 : Float(*, 3, 80, 80, 6, strides=[115200, 38400, 480, 6, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%1110), scope: lib.models.YOLOP.MCnet::/lib.models.common.Detect::model.24 # C:\\Users\\Berne/.cache\\torch\\hub\\hustvl_yolop_main\\lib\\models\\common.py:201:0\n    )  (type 'Tensor')"
          ]
        }
      ],
      "source": [
        "# Input to the model\n",
        "img = torch.randn(1,3,640,640)\n",
        "torch_out = torch_model(img)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(torch_model,               # model being run\n",
        "                  img,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"yolop.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8zGoNISR7-y"
      },
      "source": [
        "We also computed `torch_out`, the output after of the model, which we\n",
        "will use to verify that the model we exported computes the same values\n",
        "when run in ONNX Runtime.\n",
        "\n",
        "But before verifying the model\\'s output with ONNX Runtime, we will\n",
        "check the ONNX model with ONNX API. First,\n",
        "`onnx.load(\"super_resolution.onnx\")` will load the saved model and will\n",
        "output a `onnx.ModelProto` structure (a top-level file/container format\n",
        "for bundling a ML model. For more information [onnx.proto\n",
        "documentation](https://github.com/onnx/onnx/blob/master/onnx/onnx.proto).).\n",
        "Then, `onnx.checker.check_model(onnx_model)` will verify the model\\'s\n",
        "structure and confirm that the model has a valid schema. The validity of\n",
        "the ONNX graph is verified by checking the model\\'s version, the\n",
        "graph\\'s structure, as well as the nodes and their inputs and outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YfECvoKIR7-z"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"yolop.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CManRbMmR7-0"
      },
      "source": [
        "Now let\\'s compute the output using ONNX Runtime\\'s Python APIs. This\n",
        "part can normally be done in a separate process or on another machine,\n",
        "but we will continue in the same process so that we can verify that ONNX\n",
        "Runtime and PyTorch are computing the same value for the network.\n",
        "\n",
        "In order to run the model with ONNX Runtime, we need to create an\n",
        "inference session for the model with the chosen configuration parameters\n",
        "(here we use the default config). Once the session is created, we\n",
        "evaluate the model using the run() API. The output of this call is a\n",
        "list containing the outputs of the model computed by ONNX Runtime.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TmfeSCmR7-0",
        "outputId": "a9d4e1a5-3685-413b-d196-839e4c05f338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ],
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"yolop.onnx\", providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAuHUPllR7-1"
      },
      "source": [
        "We should see that the output of PyTorch and ONNX Runtime runs match\n",
        "numerically with the given precision (`rtol=1e-03` and `atol=1e-05`). As\n",
        "a side-note, if they do not match then there is an issue in the ONNX\n",
        "exporter, so please contact us in that case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZk4fiThR7-2"
      },
      "source": [
        "Running the model on an image using ONNX Runtime\n",
        "================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW947X28R7-2"
      },
      "source": [
        "So far we have exported a model from PyTorch and shown how to load it\n",
        "and run it in ONNX Runtime with a dummy tensor as an input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTq8YibgR7-3"
      },
      "source": [
        "For this tutorial, we will use a famous cat image used widely which\n",
        "looks like below\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/cat_224x224.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcfzST0MR7-3"
      },
      "source": [
        "First, let\\'s load the image, preprocess it using standard PIL python\n",
        "library. Note that this preprocessing is the standard practice of\n",
        "processing data for training/testing neural networks.\n",
        "\n",
        "We first resize the image to fit the size of the model\\'s input\n",
        "(224x224). Then we split the image into its Y, Cb, and Cr components.\n",
        "These components represent a grayscale image (Y), and the\n",
        "blue-difference (Cb) and red-difference (Cr) chroma components. The Y\n",
        "component being more sensitive to the human eye, we are interested in\n",
        "this component which we will be transforming. After extracting the Y\n",
        "component, we convert it to a tensor which will be the input of our\n",
        "model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6DgetibUA6u",
        "outputId": "6058edde-3052-4d97-f64c-5838e3ce59bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-03 11:59:13--  https://pytorch.org/tutorials/_static/img/cat_224x224.jpg\n",
            "Resolving pytorch.org (pytorch.org)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to pytorch.org (pytorch.org)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10270 (10K) [image/jpeg]\n",
            "Saving to: ‘cat.jpg’\n",
            "\n",
            "cat.jpg             100%[===================>]  10.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-05-03 11:59:14 (61.7 MB/s) - ‘cat.jpg’ saved [10270/10270]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget \"https://pytorch.org/tutorials/_static/img/cat_224x224.jpg\" -O cat.jpg\n",
        "# ! wget 'https://docs.google.com/uc?export=download&id=1emp4FIwheYnCGm1klhMVeAUxt9qAURoZ' -O alot5classes.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-aG5EdsR7-3",
        "outputId": "5d5b86ed-f109-4733-ff90-ce552a3fb4d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0.2157, 0.1961, 0.1922,  ..., 0.5294, 0.5569, 0.5686],\n",
              "          [0.2039, 0.1961, 0.1922,  ..., 0.5333, 0.5569, 0.5686],\n",
              "          [0.1961, 0.1843, 0.1843,  ..., 0.5216, 0.5412, 0.5490],\n",
              "          ...,\n",
              "          [0.6667, 0.6745, 0.6392,  ..., 0.6902, 0.6667, 0.6078],\n",
              "          [0.6392, 0.6431, 0.6235,  ..., 0.8000, 0.7608, 0.6745],\n",
              "          [0.6392, 0.6353, 0.6510,  ..., 0.8118, 0.7686, 0.6667]]]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "img = Image.open(\"./cat.jpg\")\n",
        "\n",
        "resize = transforms.Resize([224, 224])\n",
        "img = resize(img)\n",
        "\n",
        "img_ycbcr = img.convert('YCbCr')\n",
        "img_y, img_cb, img_cr = img_ycbcr.split()\n",
        "\n",
        "to_tensor = transforms.ToTensor()\n",
        "img_y = to_tensor(img_y)\n",
        "img_y.unsqueeze_(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go31Ev0pR7-4"
      },
      "source": [
        "Now, as a next step, let\\'s take the tensor representing the grayscale\n",
        "resized cat image and run the super-resolution model in ONNX Runtime as\n",
        "explained previously.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "B7DA6EykR7-5"
      },
      "outputs": [],
      "source": [
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "img_out_y = ort_outs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSiRRykWR7-6"
      },
      "source": [
        "At this point, the output of the model is a tensor. Now, we\\'ll process\n",
        "the output of the model to construct back the final output image from\n",
        "the output tensor, and save the image. The post-processing steps have\n",
        "been adopted from PyTorch implementation of super-resolution model\n",
        "[here](https://github.com/pytorch/examples/blob/master/super_resolution/super_resolve.py).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EjcbQKzuR7-6"
      },
      "outputs": [],
      "source": [
        "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
        "\n",
        "# get the output image follow post-processing step from PyTorch implementation\n",
        "final_img = Image.merge(\n",
        "    \"YCbCr\", [\n",
        "        img_out_y,\n",
        "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
        "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
        "    ]).convert(\"RGB\")\n",
        "\n",
        "# Save the image, we will compare this with the output image from mobile device\n",
        "final_img.save(\"./cat_superres_with_ort.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSjXVTydR7-7"
      },
      "source": [
        "![](https://pytorch.org/tutorials/_static/img/cat_superres_with_ort.jpg)\n",
        "\n",
        "ONNX Runtime being a cross platform engine, you can run it across\n",
        "multiple platforms and on both CPUs and GPUs.\n",
        "\n",
        "ONNX Runtime can also be deployed to the cloud for model inferencing\n",
        "using Azure Machine Learning Services. More information\n",
        "[here](https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-onnx).\n",
        "\n",
        "More information about ONNX Runtime\\'s performance\n",
        "[here](https://github.com/microsoft/onnxruntime#high-performance).\n",
        "\n",
        "For more information about ONNX Runtime\n",
        "[here](https://github.com/microsoft/onnxruntime).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
